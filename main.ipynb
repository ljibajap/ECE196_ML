{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data and store on dataframes\n",
    "movie_database = pd.read_csv('Small_Data/movies.csv')\n",
    "users_ratings = pd.read_csv('Small_Data/ratings.csv')\n",
    "tags_database = pd.read_csv('Small_Data/tags.csv')\n",
    "links_database = pd.read_csv('Small_Data/links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Display the first 10 items from the movies data set\n",
    "movie_database[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>964982703</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4.0</td>\n      <td>964981247</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>6</td>\n      <td>4.0</td>\n      <td>964982224</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>47</td>\n      <td>5.0</td>\n      <td>964983815</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>50</td>\n      <td>5.0</td>\n      <td>964982931</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Display the first 5 items from the rating data set\n",
    "users_ratings[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift users and movies ID by 1, so start at 0\n",
    "users_ratings['userId'] = users_ratings['userId'] - 1\n",
    "users_ratings['movieId'] = users_ratings['movieId'] - 1\n",
    "movie_database['movieId'] = movie_database['movieId'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              userId        movieId         rating     timestamp\n",
       "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
       "mean      325.127564   19434.295718       3.501557  1.205946e+09\n",
       "std       182.618491   35530.987199       1.042529  2.162610e+08\n",
       "min         0.000000       0.000000       0.500000  8.281246e+08\n",
       "25%       176.000000    1198.000000       3.000000  1.019124e+09\n",
       "50%       324.000000    2990.000000       3.500000  1.186087e+09\n",
       "75%       476.000000    8121.000000       4.000000  1.435994e+09\n",
       "max       609.000000  193608.000000       5.000000  1.537799e+09"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100836.000000</td>\n      <td>100836.000000</td>\n      <td>100836.000000</td>\n      <td>1.008360e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>325.127564</td>\n      <td>19434.295718</td>\n      <td>3.501557</td>\n      <td>1.205946e+09</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>182.618491</td>\n      <td>35530.987199</td>\n      <td>1.042529</td>\n      <td>2.162610e+08</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>8.281246e+08</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>176.000000</td>\n      <td>1198.000000</td>\n      <td>3.000000</td>\n      <td>1.019124e+09</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>324.000000</td>\n      <td>2990.000000</td>\n      <td>3.500000</td>\n      <td>1.186087e+09</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>476.000000</td>\n      <td>8121.000000</td>\n      <td>4.000000</td>\n      <td>1.435994e+09</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>609.000000</td>\n      <td>193608.000000</td>\n      <td>5.000000</td>\n      <td>1.537799e+09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Print ratings statistics describing numeric features\n",
    "users_ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def build_feedback_matrix(ratings,movies_list,users_list):\n",
    "    # Initiate feedback matrix with all zero ratings\n",
    "    # Get all unique users ids\n",
    "    feedback_matrix = np.zeros((len(users_list),len(movies_list)))\n",
    "    #users = pd.unique(users_ratings['userId'])\n",
    "    for user_id in users_list:\n",
    "        # Get the ratings for especific user id\n",
    "        ratings = users_ratings[users_ratings['userId'] == user_id]\n",
    "        num_ratings = len(ratings)\n",
    "        # Set the rating of all the movies that the user Id has give rating\n",
    "        for j in ratings.index:\n",
    "            movie_id = ratings['movieId'].loc[j]\n",
    "            movie_index = movie_database[movie_database['movieId'] == movie_id].index.values\n",
    "            feedback_matrix[user_id,movie_index] = ratings['rating'].loc[j]\n",
    "\n",
    "    return feedback_matrix\n",
    "\n",
    "\"\"\"\n",
    "indices = users_ratings[['userId','movieId']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Alg:\n",
    "1. Get userId list list_user\n",
    "2. Get movieId list list_movie\n",
    "3. For each user:\n",
    "    a. Get ratings by user\n",
    "    b. For each index of ratings in users_ratings dataframe:\n",
    "        i. Get movieid index (column index) in ratings['movieId']\n",
    "        ii. Append (user, movie, rating) to output list\n",
    "4. Returns 3-tuple (output_list, list_user, list_movie)\n",
    "'''\n",
    "def get_user_item_pairs():\n",
    "    list_userId = np.array(pd.unique(users_ratings['userId']))\n",
    "    list_movieId = np.array(pd.unique(movie_database['movieId']))\n",
    "    movie_index_list = pd.Index(movie_database['movieId'])\n",
    "    output_list = []\n",
    "    # index by user\n",
    "    for user_index in np.arange(0, len(list_userId)):\n",
    "        # associated user_id with user\n",
    "        user_id = list_userId[user_index]\n",
    "        # ratings by user\n",
    "        ratings = users_ratings[users_ratings['userId'] == user_id]\n",
    "        # for each row index associated with user\n",
    "        for index in ratings.index:\n",
    "            # get movie id for finding movie index\n",
    "            movie_id = users_ratings['movieId'].iloc[index]\n",
    "            # get movie index to place in list\n",
    "            movie_index = movie_index_list.get_loc(movie_id)#movie_database['movieId'].loc[movie_id]\n",
    "            # get rating\n",
    "            rating = users_ratings['rating'].iloc[index]\n",
    "            #rating = ratings['rating'].loc[index]\n",
    "            #output_list.append((user_index, movie_index, rating))\n",
    "            output_list.append([user_index,movie_index,rating])\n",
    "    \n",
    "    #output_list = np.array(output_list,dtype='i4,i4,i4')\n",
    "    data_set = pd.DataFrame(output_list,columns=['user_idx','movie_idx','rating'])\n",
    "    \n",
    "    return(data_set,list_userId,list_movieId)\n",
    "    #return (np.array(output_list, dtype='i4,i4,i4'), list_userId, list_movieId)\n",
    "#     return (np.array(output_list, dtype=[('user_index', '<i4'), ('movie_index', '<i4'), ('rating', '<i4')]), list_userId, list_movieId)\n",
    "'''\n",
    "Input:\n",
    "    S is a collection of 3-tuples (user, movie, rating)\n",
    "        user is the index of the user in list_userId\n",
    "        movie is the index of the movie in list_movieId\n",
    "        rating is the corresponding rating\n",
    "    Output: mxn feedback matrix\n",
    "        m is the length of list_userId\n",
    "        n is the length of list_movieId\n",
    "        Entry (i, j) is nonzero if list_userId[i] reviewed list_movieId[j]\n",
    "'''\n",
    "def build_feedback_matrix(data_set, list_userId_len, list_movieId_len):\n",
    "    \"\"\"\n",
    "    m = list_userId.shape[0]\n",
    "    n = list_movieId.shape[0]\n",
    "    F = np.zeros((m, n))\n",
    "    for (user_index, movie_index, rating) in S:\n",
    "        F[user_index, movie_index] = rating\n",
    "    return F\n",
    "    \"\"\"\n",
    "    feedback_matrix = np.zeros((list_userId_len,list_movieId_len))\n",
    "    for index in data_set.index:\n",
    "        user_index = data_set['user_idx'].loc[index]\n",
    "        movie_index = data_set['movie_idx'].loc[index]\n",
    "        rating = data_set['rating'].loc[index]\n",
    "        feedback_matrix[user_index,movie_index] = rating\n",
    "    \n",
    "    return feedback_matrix\n",
    "\n",
    "\n",
    "# Break the dataset into test and train sets\n",
    "# Keep a 0.1 holdout fraction to construct test\n",
    "def break_data(data,holdout_fraction=0.1):\n",
    "    #data_copy = data.copy()\n",
    "    #data_copy = data_copy.sample(frac=1)\n",
    "    #test_set = data_copy.sample(frac=holdout_fraction)\n",
    "    #train_set = data_copy[~data_copy.index.isin(test_set.index)]\n",
    "    test_set = data.sample(frac=holdout_fraction)\n",
    "    train_set = data[~data.index.isin(test_set.index)]\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the data set based on the index of user, movies bind with the respective rating\n",
    "# Build the list of usersIds\n",
    "# Build the list of movieIds\n",
    "(user_item_rating, list_userId, list_movieId)  = get_user_item_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break the data set into train and test \n",
    "train_data, test_data = break_data(user_item_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objetive function\n",
    "# Implement Mean Square Error(MSE)\n",
    "def calculate_loss(feedback_matrix,P,V):\n",
    "    #Calculate the ratings matrix approximation\n",
    "    predictions = np.dot(P,V.T)\n",
    "    # Calculate the square error for each reating\n",
    "    error_matrix = np.square((feedback_matrix - predictions))\n",
    "    # Return the mean square error over the last dimension\n",
    "    return np.mean(error_matrix)\n",
    "    #return np.sum(error_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CF_Model(object):\n",
    "    def __init__(self,users,movies):\n",
    "        self.embedding_vars = {}\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        self.list_userId = users\n",
    "        self.list_movieId = movies\n",
    "        self.num_users = users.shape[0]\n",
    "        self.num_movies = movies.shape[0]\n",
    "        self.num_features = 0\n",
    "\n",
    "    def embeddings(self):\n",
    "        return self.embedding_vars\n",
    "    \n",
    "    def build_model(self,num_features=30,mu=0,std=1):\n",
    "        \"\"\"\n",
    "            P: associative matrix btw Users and Features\n",
    "            V: associative matrix btw Movies and Features\n",
    "        \"\"\"\n",
    "        self.num_features = num_features\n",
    "        P = np.random.normal(loc=mu,scale=std,size=(self.num_users,num_features))\n",
    "        V = np.random.normal(loc=mu,scale=std,size=(self.num_movies,num_features))\n",
    "        self.embedding_vars['P'] = P\n",
    "        self.embedding_vars['V'] = V\n",
    "    \n",
    "    def train(self,data_set,num_iter=100,learning_rate=0.00002):\n",
    "        train_data, test_data =  break_data(data_set)\n",
    "        train_matrix = build_feedback_matrix(train_data,self.num_users,self.num_movies)\n",
    "        test_matrix = build_feedback_matrix(test_data,self.num_users,self.num_movies)\n",
    "        P = self.embedding_vars['P']\n",
    "        V = self.embedding_vars['V']\n",
    "\n",
    "        for epoch in range(num_iter):\n",
    "            \"\"\"\n",
    "            for i in range(self.num_users):\n",
    "                for j in range(self.num_movies):\n",
    "                    if train_matrix[i,j] > 0:\n",
    "                        eij = train_matrix[i,j] - np.dot(P[i,:],V[:,j])\n",
    "                        \n",
    "                        for k in range(self.num_features):\n",
    "                            P[i,k] = P[i,k] + 2*learning_rate * eij * V[k,j]\n",
    "                            V[j,k] = V[j,k] + 2*learning_rate * eij * P[k,j]\n",
    "            \"\"\"\n",
    "            E = train_matrix - np.dot(P,V.T)\n",
    "            P = P + learning_rate * (2 * E @ V)\n",
    "            V = V + learning_rate * (2 * E.T @ P)\n",
    "            train_error = calculate_loss(train_matrix,P,V)\n",
    "            test_error = calculate_loss(test_matrix,P,V)\n",
    "            print(\"i: \" + str(epoch) + \" Train Loss: \" + str(train_error) + \" - Test Loss: \" + str(test_error))\n",
    "            self.train_loss.append(train_error)\n",
    "            self.test_loss.append(test_error)\n",
    "        self.embedding_vars['P'] = P\n",
    "        self.embedding_vars['V'] = V\n",
    "    \n",
    "    def plot_loss():\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle('Loss vs Number of Epochs')\n",
    "        ax = fig.add_subplot(111)\n",
    "        x1 = np.arange(len(self.train_loss))\n",
    "        x2 = np.arange(len(self.test_loss))\n",
    "        ax.plot(x1, self.train_loss, label='Train Data')\n",
    "        ax.plot(x2, self.test_loss, label='Test Data')\n",
    "        ax.set_ylabel('MSE Loss')\n",
    "        ax.set_xlabel('Epoch Number')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CF_Model(list_userId, list_movieId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "i: 0 Train Loss: 36.024946881393866 - Test Loss: 35.85338535526406\n",
      "i: 1 Train Loss: 133.34063197123535 - Test Loss: 133.15110164198924\n",
      "i: 2 Train Loss: 14597.738039573645 - Test Loss: 14597.717633862016\n",
      "i: 3 Train Loss: 272839088046881.5 - Test Loss: 272839088035904.3\n",
      "i: 4 Train Loss: 1.2461576918847275e+59 - Test Loss: 1.2461576918847275e+59\n",
      "i: 5 Train Loss: 2.0748891385000706e+248 - Test Loss: 2.0748891385000706e+248\n",
      "i: 6 Train Loss: inf - Test Loss: inf\n",
      "i: 7 Train Loss: inf - Test Loss: inf\n",
      "i: 8 Train Loss: nan - Test Loss: nan\n",
      "i: 9 Train Loss: nan - Test Loss: nan\n",
      "i: 10 Train Loss: nan - Test Loss: nan\n",
      "i: 11 Train Loss: nan - Test Loss: nan\n",
      "i: 12 Train Loss: nan - Test Loss: nan\n",
      "i: 13 Train Loss: nan - Test Loss: nan\n",
      "i: 14 Train Loss: nan - Test Loss: nan\n",
      "i: 15 Train Loss: nan - Test Loss: nan\n",
      "i: 16 Train Loss: nan - Test Loss: nan\n",
      "i: 17 Train Loss: nan - Test Loss: nan\n",
      "i: 18 Train Loss: nan - Test Loss: nan\n",
      "i: 19 Train Loss: nan - Test Loss: nan\n",
      "i: 20 Train Loss: nan - Test Loss: nan\n",
      "i: 21 Train Loss: nan - Test Loss: nan\n",
      "i: 22 Train Loss: nan - Test Loss: nan\n",
      "i: 23 Train Loss: nan - Test Loss: nan\n",
      "i: 24 Train Loss: nan - Test Loss: nan\n",
      "i: 25 Train Loss: nan - Test Loss: nan\n",
      "i: 26 Train Loss: nan - Test Loss: nan\n",
      "i: 27 Train Loss: nan - Test Loss: nan\n",
      "i: 28 Train Loss: nan - Test Loss: nan\n",
      "i: 29 Train Loss: nan - Test Loss: nan\n",
      "i: 30 Train Loss: nan - Test Loss: nan\n",
      "i: 31 Train Loss: nan - Test Loss: nan\n",
      "i: 32 Train Loss: nan - Test Loss: nan\n",
      "i: 33 Train Loss: nan - Test Loss: nan\n",
      "i: 34 Train Loss: nan - Test Loss: nan\n",
      "i: 35 Train Loss: nan - Test Loss: nan\n",
      "i: 36 Train Loss: nan - Test Loss: nan\n",
      "i: 37 Train Loss: nan - Test Loss: nan\n",
      "i: 38 Train Loss: nan - Test Loss: nan\n",
      "i: 39 Train Loss: nan - Test Loss: nan\n",
      "i: 40 Train Loss: nan - Test Loss: nan\n",
      "i: 41 Train Loss: nan - Test Loss: nan\n",
      "i: 42 Train Loss: nan - Test Loss: nan\n",
      "i: 43 Train Loss: nan - Test Loss: nan\n",
      "i: 44 Train Loss: nan - Test Loss: nan\n",
      "i: 45 Train Loss: nan - Test Loss: nan\n",
      "i: 46 Train Loss: nan - Test Loss: nan\n",
      "i: 47 Train Loss: nan - Test Loss: nan\n",
      "i: 48 Train Loss: nan - Test Loss: nan\n",
      "i: 49 Train Loss: nan - Test Loss: nan\n",
      "i: 50 Train Loss: nan - Test Loss: nan\n",
      "i: 51 Train Loss: nan - Test Loss: nan\n",
      "i: 52 Train Loss: nan - Test Loss: nan\n",
      "i: 53 Train Loss: nan - Test Loss: nan\n",
      "i: 54 Train Loss: nan - Test Loss: nan\n",
      "i: 55 Train Loss: nan - Test Loss: nan\n",
      "i: 56 Train Loss: nan - Test Loss: nan\n",
      "i: 57 Train Loss: nan - Test Loss: nan\n",
      "i: 58 Train Loss: nan - Test Loss: nan\n",
      "i: 59 Train Loss: nan - Test Loss: nan\n",
      "i: 60 Train Loss: nan - Test Loss: nan\n",
      "i: 61 Train Loss: nan - Test Loss: nan\n",
      "i: 62 Train Loss: nan - Test Loss: nan\n",
      "i: 63 Train Loss: nan - Test Loss: nan\n",
      "i: 64 Train Loss: nan - Test Loss: nan\n",
      "i: 65 Train Loss: nan - Test Loss: nan\n",
      "i: 66 Train Loss: nan - Test Loss: nan\n",
      "i: 67 Train Loss: nan - Test Loss: nan\n",
      "i: 68 Train Loss: nan - Test Loss: nan\n",
      "i: 69 Train Loss: nan - Test Loss: nan\n",
      "i: 70 Train Loss: nan - Test Loss: nan\n",
      "i: 71 Train Loss: nan - Test Loss: nan\n",
      "i: 72 Train Loss: nan - Test Loss: nan\n",
      "i: 73 Train Loss: nan - Test Loss: nan\n",
      "i: 74 Train Loss: nan - Test Loss: nan\n",
      "i: 75 Train Loss: nan - Test Loss: nan\n",
      "i: 76 Train Loss: nan - Test Loss: nan\n",
      "i: 77 Train Loss: nan - Test Loss: nan\n",
      "i: 78 Train Loss: nan - Test Loss: nan\n",
      "i: 79 Train Loss: nan - Test Loss: nan\n",
      "i: 80 Train Loss: nan - Test Loss: nan\n",
      "i: 81 Train Loss: nan - Test Loss: nan\n",
      "i: 82 Train Loss: nan - Test Loss: nan\n",
      "i: 83 Train Loss: nan - Test Loss: nan\n",
      "i: 84 Train Loss: nan - Test Loss: nan\n",
      "i: 85 Train Loss: nan - Test Loss: nan\n",
      "i: 86 Train Loss: nan - Test Loss: nan\n",
      "i: 87 Train Loss: nan - Test Loss: nan\n",
      "i: 88 Train Loss: nan - Test Loss: nan\n",
      "i: 89 Train Loss: nan - Test Loss: nan\n",
      "i: 90 Train Loss: nan - Test Loss: nan\n",
      "i: 91 Train Loss: nan - Test Loss: nan\n",
      "i: 92 Train Loss: nan - Test Loss: nan\n",
      "i: 93 Train Loss: nan - Test Loss: nan\n",
      "i: 94 Train Loss: nan - Test Loss: nan\n",
      "i: 95 Train Loss: nan - Test Loss: nan\n",
      "i: 96 Train Loss: nan - Test Loss: nan\n",
      "i: 97 Train Loss: nan - Test Loss: nan\n",
      "i: 98 Train Loss: nan - Test Loss: nan\n",
      "i: 99 Train Loss: nan - Test Loss: nan\n"
     ]
    }
   ],
   "source": [
    "model.train(user_item_rating,num_iter=100,learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}